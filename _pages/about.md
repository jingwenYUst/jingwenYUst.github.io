---
permalink: /
title: "Jingwen Yu"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi there, I am Jingwen YU (‰∏≠ÊñáÂêçÔºö‰∫éÈùñÊñá), a Ph.D. candidate at [Cheng Kar-Shun Robotics Institute (CKSRI)](https://ri.hkust.edu.hk/), Hong Kong University of Science and Technology (HKUST) and affiliated with [Shenzhen Key Laboratory of Robotics and Computer Vision Lab](https://rcvlab.eee.sustech.edu.cn/) at Southern University of Science and Technology (SUSTech). I am co-supervised by [Prof. Ping TAN](https://ece.hkust.edu.hk/pingtan) and [Chair Prof. Hong ZHANG (SUSTech)](https://eee.sustech.edu.cn/?view=%E5%BC%A0%E5%AE%8F&jsid=18&lang=en). I work closely with [Dr. Jianhao JIAO](https://gogojjh.github.io/), [Dr. Hengli WANG](https://hlwang1124.github.io/), [Mr. Hanjing YE](https://medlartea.github.io/), and [Mr. Chao TANG](https://mkt1412.github.io/). I was with the Intelligent Autonomous Driving Center (IADC) and [RAM-Lab](https://ram-lab.com/), led by Prof. [Ming LIU](https://facultyprofiles.hkust-gz.edu.cn/faculty-personal-page/LIU-Ming/eelium), where I got the chance to work on autonomous vehicles and quadruped robots. Besides, I am also interested in task-oriented grasping, check out the [projects section](/projects/) for more details. I earned my B.Eng. of Information Engineering from Dept. of Electronic and Electrical Engineering under advising from Chair Prof. Hong Zhang and Prof. Yajun Yu.

Now, I teach robots to **locate** themselves in changing environments, focusing on:
- Visual Place Recognition / Loop Closure Detection
- Visual Localization and Image Matching
- Visual SLAM

Reach out if you are interested in my research!

News
======
- *Jul/2024* : üéâ Jiayi Yang (Êù®‰Ω≥ÊÄ°) and Yongqi Shi (ÊñΩÊ∞∏Á•∫) graduated from SUSTech and will be going to UTokyo and Duke University. They completed their final-year projects on loop closure verification with me.

- *Jun/2024* : üéâ A paper "GV-Bench: Benchmarking Local Feature Matching for Geometric Verification of Long-term Loop Closure Detection" is accepted to IROS 2024. [Arxiv](https://arxiv.org/abs/2407.11736), [Code](https://github.com/jarvisyjw/GV-Bench).

- *Apr/2024* : üéâ Our dataset [FusionPortableV2](https://arxiv.org/abs/2404.08563) is released on arxiv! Check out our [website](https://fusionportable.github.io/dataset/fusionportable_v2/) see how can FPV2 boost your research toward Generalized SLAM.

Selected Publication:
======
Full publication list is available on [google scholar](https://scholar.google.com/citations?user=fu52r0cAAAAJ&hl=zh-CN).
<!-- ## Loop Closure / Place Recognition Verification -->
<html>
  <h3>Verification of Loop Closure Detection / Place Recognition</h3>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:20px;width:25%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
              <img src="../images/gvbench.jpg" alt="hpp" style="border-style: none" >
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
                <papertitle>GV-Bench: Benchmarking Local Feature Matching for Geometric Verification of Long-term Loop Closure Detection
                </papertitle>
              <br>
                <strong>Jingwen Yu</strong>, Hanjing Ye, Jianhao Jiao, Ping Tan, Hong Zhang
              <br>
              <em>IEEE/RSJ International Conference on Intelligent Robots and Systems, 2024.</em><br>
              <!-- <a href="https://ieeexplore.ieee.org/document/10243098">Paper</a> / -->
              <a href="https://arxiv.org/abs/2407.11736"><img src="https://img.shields.io/badge/ArXiv-2407.11736-004088.svg"/></a>
              <a href="https://jarvisyjw.github.io/GV-Bench/"><img alt="Static Badge" src="https://img.shields.io/badge/Project-Page-blue?style=flat"></a>
              <a href="https://github.com/jarvisyjw/GV-Bench"><img alt="Code" src="https://img.shields.io/github/stars/jarvisyjw/GV-Bench" /></a>
              <a href="https://mp.weixin.qq.com/s/edUw7vLep0zmve0Uj3IzkQ"><img alt="Static Badge" src="https://img.shields.io/badge/‰∏≠Êñá‰ªãÁªçÔºàby 3DËßÜËßâ‰πãÂøÉÔºâ-blue?style=flat"></a>
              <!-- <a href="https://youtu.be/VtQGvuDZSec"><img alt="Youtube" src="https://img.shields.io/badge/Video-Youtube-red"/></a> -->
              <!-- <a href="https://www.bilibili.com/video/BV1By421v7S8"><img alt="Bilibili" src="https://img.shields.io/badge/Video-Bilibili-blue"/></a> -->
            </td>
          </tr>
    </table>
  <h3>Multi-Sensor Fusion SLAM</h3>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
        <td style="padding:20px;width:25%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
          <img src="../images/fpv2.png" alt="hpp" style="border-style: none" >
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
            <papertitle>FusionPortableV2: A Unified Multi-Sensor Dataset for Generalized SLAM Across Diverse Platforms and Scalable Environments
            </papertitle>
          <br>
            Hexiang Wei, Jianhao Jiao, Xiangcheng Hu, <strong>Jingwen Yu</strong>, Xupeng Xie, Jin Wu, Yilong Zhu, Yuxuan Liu, Lujia Wang, Ming Liu
          <br>
          <em>Under Review</em><br>
          <!-- <a href="https://ieeexplore.ieee.org/document/10243098">Paper</a> / -->
          <a href="https://arxiv.org/abs/2404.08563"><img src="https://img.shields.io/badge/ArXiv-2403.10821-004088.svg"/></a>
          <a href="https://fusionportable.github.io/dataset/fusionportable_v2/"><img alt="Static Badge" src="https://img.shields.io/badge/Project-Page-blue?style=flat"></a>
          <a href="https://github.com/fusionportable"><img alt="Code" src="https://img.shields.io/github/stars/fusionportable"></a>
          <a href="https://www.bilibili.com/video/BV1YT421m7VG/?vd_source=d3db6b42a5234397edfd9fe138b66f53"><img alt="Bilibili" src="https://img.shields.io/badge/Video-Bilibili-blue"/></a>
          <a href="https://mp.weixin.qq.com/s/ltE1skOC4Bb1ECUh4PChNA"><img alt="Static Badge" src="https://img.shields.io/badge/‰∏≠Êñá‰ªãÁªçÔºàby Ëá™Âä®È©æÈ©∂‰∏ìÊ†èÔºâ-blue?style=flat"></a>
        </td>
      </tr>
    </table>
  <h3>Task-Oriented Grasping</h3>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
        <td style="padding:20px;width:25%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
          <img src="../images/grasping.png" alt="hpp" style="border-style: none" >
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle;border-left-style:none;border-bottom-style:none;border-top-style:none;border-right-style:none">
            <papertitle>Relationship Oriented Semantic Scene Understanding for Daily Manipulation Tasks
            </papertitle>
          <br>
            Chao Tang, <strong>Jingwen Yu</strong>, Weinan Chen, Bingyi Xia, Hong Zhang
          <br>
          <em>IEEE/RSJ International Conference on Intelligent Robots and Systems, 2022.</em><br>
          <a href="https://ieeexplore.ieee.org/abstract/document/9981960"><img src="https://img.shields.io/badge/IEEE/RSJ-Paper-004088"></a>
          <!-- <a href="https://arxiv.org/abs/2404.08563"><img src="https://img.shields.io/badge/ArXiv-2403.10821-004088.svg"/></a> -->
          <!-- <a href="https://github.com/fusionportable"><img alt="Code" src="https://img.shields.io/github/stars/fusionportable"></a> -->
          <a href="https://docs.google.com/presentation/d/10UzGuVYANGRN6nSMplZWPKoEPs4NUu-XantlLYUSQsg/edit#slide=id.g14b6bc499f4_4_35"><img src="https://img.shields.io/badge/Slides-grey"></a>
          <a href="https://drive.google.com/file/d/1wL3XmJt_-VYIq7cO1lMo0I09TyBVkuGw/view"><img src="https://img.shields.io/badge/Video-grey"></a>
        </td>
      </tr>
  </table>
</html>

Education
======
- Hong Kong University of Science and Technology, Sep, 2021-present
  - Ph.D. Candidate in Electronic and Computer Engineering

- Southern University of Science and Technology, Sep, 2017- Jun, 2021
  - B.Eng. in Electronic and Electrical Engineering **(with Magna Cum Laude)**
  - **National Scholarship of China**

- National University of Singapore, Jun, 2019 - Aug, 2019
  - Undergraduate Visiting Student

- High School Attached To Shandong Normal University, Sept, 2014 - Jun, 2017

Academic Services
======
- IEEE ICRA 2024 Reviewer
- IEEE/RSJ IROS 2024 Reviewer
- IEEE Intelligent Vehicles Symposium 2022, 2023 Reviewer
- IEEE ICRA 2021 Organizing Committee & Outstanding Volunteer
- MICCAI 2018 Volunteer

Teaching
======
I have always enjoyed teaching since my undergraduate.
- Graduate Teaching Assistant, HKUST
  - ELEC3120 Computer Communication Network
- Undergraduate Teaching Assistant, SUSTech
  - EE346 Mobile Robot Navigation
